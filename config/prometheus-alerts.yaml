apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-custom-alerts
  namespace: monitoring
data:
  custom-alerts.yaml: |
    groups:
    - name: kubernetes_cluster_alerts
      interval: 30s
      rules:
      
      # Node Alerts
      - alert: NodeDown
        expr: up{job="kubernetes-nodes"} == 0
        for: 5m
        labels:
          severity: critical
          category: infrastructure
        annotations:
          summary: "Node {{ $labels.instance }} is down"
          description: "Kubernetes node {{ $labels.instance }} has been down for more than 5 minutes."
      
      - alert: NodeHighCPU
        expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% (current value: {{ $value }}%)"
      
      - alert: NodeHighMemory
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85% (current value: {{ $value }}%)"
      
      - alert: NodeDiskSpaceLow
        expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 80
        for: 5m
        labels:
          severity: warning
          category: storage
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk usage is above 80% on {{ $labels.mountpoint }} (current value: {{ $value }}%)"
      
      # Pod Alerts
      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
        for: 5m
        labels:
          severity: critical
          category: application
        annotations:
          summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has restarted {{ $value }} times in the last 15 minutes."
      
      - alert: PodNotReady
        expr: kube_pod_status_phase{phase!="Running",phase!="Succeeded"} == 1
        for: 10m
        labels:
          severity: warning
          category: application
        annotations:
          summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} not ready"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in {{ $labels.phase }} state for more than 10 minutes."
      
      - alert: PodHighCPU
        expr: sum(rate(container_cpu_usage_seconds_total{container!=""}[5m])) by (pod, namespace) > 0.8
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "High CPU usage in pod {{ $labels.namespace }}/{{ $labels.pod }}"
          description: "Pod CPU usage is above 80% (current value: {{ $value }})"
      
      - alert: PodHighMemory
        expr: sum(container_memory_usage_bytes{container!=""}) by (pod, namespace) / sum(container_spec_memory_limit_bytes{container!=""}) by (pod, namespace) > 0.85
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "High memory usage in pod {{ $labels.namespace }}/{{ $labels.pod }}"
          description: "Pod memory usage is above 85% of limit (current value: {{ $value }}%)"
      
      # Deployment Alerts
      - alert: DeploymentReplicasMismatch
        expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
        for: 10m
        labels:
          severity: warning
          category: application
        annotations:
          summary: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} replicas mismatch"
          description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for 10 minutes."
      
      # Container Alerts
      - alert: ContainerKilled
        expr: time() - container_last_seen > 60
        for: 5m
        labels:
          severity: warning
          category: application
        annotations:
          summary: "Container {{ $labels.name }} killed"
          description: "Container {{ $labels.name }} in pod {{ $labels.pod }} was killed."
      
      # Persistent Volume Alerts
      - alert: PersistentVolumeSpaceLow
        expr: (kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes) * 100 < 20
        for: 5m
        labels:
          severity: warning
          category: storage
        annotations:
          summary: "PersistentVolume {{ $labels.persistentvolumeclaim }} low on space"
          description: "PersistentVolume {{ $labels.persistentvolumeclaim }} has less than 20% space available (current: {{ $value }}%)"
      
      # API Server Alerts
      - alert: KubernetesAPIServerDown
        expr: up{job="kubernetes-apiservers"} == 0
        for: 5m
        labels:
          severity: critical
          category: infrastructure
        annotations:
          summary: "Kubernetes API Server is down"
          description: "Kubernetes API Server has been down for more than 5 minutes."
      
      - alert: KubernetesAPIHighLatency
        expr: histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{verb!="WATCH"}[5m])) by (verb, le)) > 1
        for: 10m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "Kubernetes API Server high latency"
          description: "99th percentile latency for {{ $labels.verb }} requests is above 1s (current: {{ $value }}s)"
      
    - name: prometheus_alerts
      interval: 30s
      rules:
      
      # Prometheus Self-Monitoring
      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 5m
        labels:
          severity: critical
          category: monitoring
        annotations:
          summary: "Prometheus is down"
          description: "Prometheus has been down for more than 5 minutes."
      
      - alert: PrometheusConfigReloadFailed
        expr: prometheus_config_last_reload_successful == 0
        for: 5m
        labels:
          severity: warning
          category: monitoring
        annotations:
          summary: "Prometheus configuration reload failed"
          description: "Prometheus configuration reload has failed. Check the logs."
      
      - alert: PrometheusTooManyRestarts
        expr: changes(process_start_time_seconds{job="prometheus"}[15m]) > 2
        for: 5m
        labels:
          severity: warning
          category: monitoring
        annotations:
          summary: "Prometheus restarting too frequently"
          description: "Prometheus has restarted {{ $value }} times in the last 15 minutes."
      
      - alert: PrometheusTargetDown
        expr: up == 0
        for: 5m
        labels:
          severity: warning
          category: monitoring
        annotations:
          summary: "Prometheus target {{ $labels.job }} is down"
          description: "{{ $labels.job }} target has been down for more than 5 minutes."
      
    - name: grafana_alerts
      interval: 30s
      rules:
      
      # Grafana Monitoring
      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 5m
        labels:
          severity: warning
          category: monitoring
        annotations:
          summary: "Grafana is down"
          description: "Grafana has been down for more than 5 minutes."

